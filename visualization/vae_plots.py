# -*- coding: utf-8 -*-
"""vae_plots.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IDRvGpKejFJ1-CpRbfdP28CylPqRSGVC
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df_exp = pd.read_json('/content/experiment_results.json')
df_info = pd.read_json('/content/infoVAE_results.json')
df_mmd  = pd.read_json('/content/mmd_curves.json')

df_mmd

import matplotlib.pyplot as plt

# number of evals to skip
SKIP = 10

# trim off the first SKIP rows
df_trim = df_mmd.iloc[SKIP:, :]

# x-axis is the evaluation index
iters = df_trim.index

# your desired legend/plot order
desired_order = [
    "Fixed λ=500, α=0.5",
    "Fixed λ=1000, α=0.5",
    "Fixed λ=500, α=0.0",
    "Fixed λ=1000, α=0.0",
    "Adaptive λ only",
    "Fixed λ=1000, α=1.0",
    "Fixed λ=500, α=1.0",
    "Adaptive α only",
    "Adaptive λ and α"
]

fig, ax = plt.subplots(figsize=(14, 9))
for name in desired_order:
    if name in df_trim.columns:
        ax.plot(iters, df_trim[name], linewidth=2, label=name)

ax.set_xlabel('Iteration', fontsize=14)
ax.set_ylabel('MMD (Validation Set Average)', fontsize=14)
ax.set_yscale('log')
ax.grid(which='both', linestyle='--', alpha=0.7)
ax.set_title('MMD vs. Training Iterations', fontsize=16)

# draw legend in the upper‐right, but anchored lower (y=0.9)
ax.legend(
    fontsize=14,
    handlelength=2,
    handletextpad=1.0,
    loc='upper right',
    bbox_to_anchor=(0.98, 0.56),
    borderaxespad=0.0
)

plt.tight_layout()
plt.show()

df_info

import numpy as np
import matplotlib.pyplot as plt

# settings
divergences = df_info.index.tolist()
dims        = [2, 5, 10, 20, 40, 60, 80]

# pick up num_epochs from the first train_mmd_hist entry
example_hist = df_info.loc[divergences[0], "train_mmd_hist"]
epoch_key    = dims[0]
sample_list  = example_hist.get(epoch_key, example_hist.get(str(epoch_key)))
num_epochs   = len(sample_list)

# define one marker per divergence
markers = ['o', 's', 'v', 'X', 'D']

# ──────────────────────────────────────────────────────────────────────────────
# a) train‐MMD vs epoch at z_dim=20
plt.figure(figsize=(6,4))
for i, name in enumerate(divergences):
    hist_dict = df_info.loc[name, "train_mmd_hist"]
    mmd_list  = hist_dict.get(20, hist_dict.get(str(20)))
    plt.plot(
        range(1, num_epochs+1),
        mmd_list,
        marker=markers[i % len(markers)],
        linestyle='-',
        label=name
    )
plt.xlabel('Epoch')
plt.ylabel('Avg batch RBF-MMD')
plt.title('Train MMD vs Epoch (z_dim=20)')
plt.yscale('log')
plt.grid(which='both', ls='--', alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()


# ──────────────────────────────────────────────────────────────────────────────
# b) validation MMD vs latent dim
plt.figure(figsize=(6,4))
for i, name in enumerate(divergences):
    val_list = df_info.loc[name, "validation_mmd"]
    plt.plot(
        dims,
        val_list,
        marker=markers[i % len(markers)],
        linestyle='-',
        label=name
    )
plt.xscale('log')
plt.yscale('log')
plt.xticks(dims, labels=dims)
plt.xlabel('Latent Dim')
plt.ylabel('Val RBF-MMD')
plt.title('Validation MMD vs Latent Dim')
plt.grid(which='both', ls='--', alpha=0.3)
plt.legend(fontsize=11)
plt.tight_layout()
plt.show()


# ──────────────────────────────────────────────────────────────────────────────
# c) semi‐sup error vs latent dim
plt.figure(figsize=(6,4))
for i, name in enumerate(divergences):
    err_list = df_info.loc[name, "semi_sup_error"]
    plt.plot(
        dims,
        err_list,
        marker=markers[i % len(markers)],
        linestyle='-',
        label=name
    )
plt.xscale('log')
plt.yscale('log')
plt.xticks(dims, labels=dims)
plt.xlabel('Latent Dim')
plt.ylabel('Class Error')
plt.title('Semi-supervised Error vs Latent Dim')
plt.grid(which='both', ls='--', alpha=0.3)
plt.tight_layout()
plt.show()


# ──────────────────────────────────────────────────────────────────────────────
# d) training time vs latent dim → grouped bar chart
plt.figure(figsize=(8,5))
n_models    = len(divergences)
bar_width   = 0.8 / n_models
x_positions = np.arange(len(dims))

for i, name in enumerate(divergences):
    time_dict = df_info.loc[name, "train_times"]
    times     = [time_dict.get(d, time_dict.get(str(d))) for d in dims]
    plt.bar(
        x_positions + i*bar_width,
        times,
        width=bar_width,
        label=name
    )

plt.xticks(
    x_positions + bar_width*(n_models-1)/2,
    labels=dims
)
plt.xlabel('Latent Dim')
plt.ylabel('Train Time (s)')
plt.title('Training Time vs Latent Dim (Grouped by Model)')
plt.legend(loc='upper left', bbox_to_anchor=(1,1))
plt.grid(axis='y', ls='--', alpha=0.3)
plt.tight_layout()
plt.show()

df_exp

import numpy as np
import matplotlib.pyplot as plt

# 1) extract dims from the `dims` row
dims = df_exp.loc['dims', '_meta']

# 2) pick experiments to include (drop `_meta` plus any you want to exclude)
exclude = {"ELBOVAE", "BetaVAE", "_meta"}
models  = [c for c in df_exp.columns if c not in exclude]

# assign a distinct marker to each model
markers = ['o', 's', 'v', 'P', 'X', 'D']
model_markers = {name: markers[i % len(markers)] for i, name in enumerate(models)}

def get_curve(row_key, name):
    raw = df_exp.loc[row_key, name]
    if not isinstance(raw, (list, np.ndarray)):
        return None
    curve = raw
    for _ in range(3):
        if hasattr(curve, '__len__') and len(curve) == len(dims):
            return curve
        if isinstance(curve, (list, np.ndarray)) and len(curve) == 1:
            curve = curve[0]
        else:
            break
    if hasattr(curve, '__len__') and len(curve) == len(dims):
        return curve
    raise ValueError(
        f"Could not unpack a length-{len(dims)} curve for {row_key}/{name}; got {type(curve)} of length {getattr(curve,'__len__',None)}"
    )

# ──────────────────────────────────────────────────────────────────────────────
# a) Validation MMD vs Latent Dim
plt.figure(figsize=(6,4))
for name in models:
    curve = get_curve('mmd', name)
    if curve is None:
        continue
    plt.plot(
        dims, curve,
        marker=model_markers[name],
        linestyle='-',
        label=name
    )
plt.xscale('log')
plt.xticks(dims, labels=dims)
plt.xlabel('Latent Dim')
plt.ylabel('Validation RBF-MMD')
plt.title('Validation MMD vs Latent Dim')
plt.grid(which='both', linestyle='--', alpha=0.5)
plt.legend(loc='best', fontsize=11)
plt.tight_layout()
plt.show()

# b) Reconstruction BCE vs Latent Dim
plt.figure(figsize=(6,4))
for name in models:
    curve = get_curve('recon', name)
    if curve is None:
        continue
    plt.plot(
        dims, curve,
        marker=model_markers[name],
        linestyle='-',
        label=name
    )
plt.xscale('log')
plt.xticks(dims, labels=dims)
plt.xlabel('Latent Dim')
plt.ylabel('Test-set BCE')
plt.title('Reconstruction Error vs Latent Dim')
plt.grid(which='both', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# c) Semi-supervised Error vs Latent Dim
plt.figure(figsize=(6,4))
for name in models:
    curve = get_curve('ss_err', name)
    if curve is None:
        continue
    plt.plot(
        dims, curve,
        marker=model_markers[name],
        linestyle='-',
        label=name
    )
plt.xscale('log')
plt.xticks(dims, labels=dims)
plt.xlabel('Latent Dim')
plt.ylabel('Classification Error')
plt.title('Semi-supervised Error vs Latent Dim')
plt.grid(which='both', linestyle='--', alpha=0.5)
plt.legend(loc='best', fontsize=11)
plt.tight_layout()
plt.show()

# d) Training Time vs Latent Dim
plt.figure(figsize=(6,4))
for name in models:
    curve = get_curve('train_time', name)
    if curve is None:
        continue
    plt.plot(
        dims, curve,
        marker=model_markers[name],
        linestyle='-',
        label=name
    )
plt.xscale('log')
plt.xticks(dims, labels=dims)
plt.xlabel('Latent Dim')
plt.ylabel('Train Time (s)')
plt.title('Training Time vs Latent Dim')
plt.grid(which='both', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

